import * as tf from "@tensorflow/tfjs-node";
import fs from "fs";
import path from "path";
import { fileURLToPath } from 'url';


const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
async function checkModel() {
  console.log("ðŸ” Checking TensorFlow.js Node setup...");
  console.log("ðŸ“¦ TensorFlow.js version:", tf.version);
  console.log("ðŸ”§ Node.js version:", process.version);
  
  const modelPath = "model/model.json";

  console.log("ðŸ“ Model path:", modelPath);
  
  // Check if model files exist
  if (!fs.existsSync(modelPath)) {
    console.error("âŒ Model file not found at:", modelPath);
    console.log("ðŸ“ Make sure you have the following files:");
    console.log("   - model/model.json");
    console.log("   - model/model_weights.bin (or similar weight files)");
    return false;
  }
  
  console.log("âœ… Model file found");
  
  // Check model.json content
  try {
    const modelConfig = JSON.parse(fs.readFileSync(modelPath, 'utf8'));
    console.log("ðŸ“‹ Model config preview:");
    console.log("   - Format:", modelConfig.format || "unknown");
    console.log("   - Generated by:", modelConfig.generatedBy || "unknown");
    console.log("   - Weights manifest entries:", modelConfig.weightsManifest?.length || 0);
    
    
    // Check weight files
    if (modelConfig.weightsManifest) {
      for (const weightGroup of modelConfig.weightsManifest) {
        for (const path of weightGroup.paths) {
          const weightPath = "model/model.json";
          if (fs.existsSync(weightPath)) {
            const stats = fs.statSync(weightPath);
            console.log(`   âœ… ${path} (${(stats.size / 1024 / 1024).toFixed(2)} MB)`);
          } else {
            console.log(`   âŒ ${path} (missing)`);
          }
        }
      }
    }
    
  } catch (err) {
    console.error("âŒ Error reading model config:", err.message);
    return false;
  }
  
  // Try to load the model
  console.log("\nðŸ”„ Attempting to load model...");
  try {
    const model = await tf.loadGraphModel(`file://${modelPath}`);
    console.log("âœ… Model loaded successfully!");
    
    console.log("ðŸ“Š Model details:");
    console.log("   - Inputs:", model.inputs.length);
    model.inputs.forEach((input, i) => {
      console.log(`     Input ${i}: shape ${JSON.stringify(input.shape)}, dtype: ${input.dtype}`);
    });
    
    console.log("   - Outputs:", model.outputs.length);
    model.outputs.forEach((output, i) => {
      console.log(`     Output ${i}: shape ${JSON.stringify(output.shape)}, dtype: ${output.dtype}`);
    });
    
    // Test prediction dengan dummy data
    console.log("\nðŸ§ª Testing prediction with dummy data...");
    const dummyInput = tf.randomNormal([1, 224, 224, 3]);
    const prediction = model.predict(dummyInput);
    
    if (prediction instanceof tf.Tensor) {
      console.log("âœ… Prediction successful!");
      console.log("   - Output shape:", prediction.shape);
      const data = await prediction.data();
      console.log("   - Output size:", data.length);
      console.log("   - Sample values:", Array.from(data.slice(0, 5)).map(x => x.toFixed(4)));
      
      prediction.dispose();
    } else {
      console.log("âš ï¸ Unexpected prediction output type:", typeof prediction);
    }
    
    dummyInput.dispose();
    model.dispose();
    
    console.log("\nðŸŽ‰ Model check completed successfully!");
    return true;
    
  } catch (err) {
    console.error("âŒ Error loading model:", err.message);
    console.error("Stack trace:", err.stack);
    return false;
  }
}

// Run the check
checkModel().then((success) => {
  if (success) {
    console.log("\nâœ¨ Your model is ready to use!");
    process.exit(0);
  } else {
    console.log("\nðŸš¨ Model check failed. Please fix the issues above.");
    process.exit(1);
  }
}).catch((err) => {
  console.error("ðŸš¨ Unexpected error:", err);
  process.exit(1);
});